{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e34010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "558e5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = torch.load(\"./MNIST_pair/training_dict.pt\")\n",
    "tup = torch.load(\"./MNIST_pair/training.pt\")\n",
    "with open('training_dict.pkl', 'rb') as f:\n",
    "    pdic = pickle.load(f)\n",
    "with open('training.pkl', 'rb') as f:\n",
    "    ptup = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save('./MNIST_pair/training_tuple.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4f3bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "696517bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_tuple.pkl', 'wb') as f:\n",
    "    pickle.dump(tup, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6576ba6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for (pk, pv), (ok, ov) in zip(pdic.items(), dic.items()):\n",
    "    assert pv.numel() == ov.numel()\n",
    "    assert (pv == ov).sum() / pv.numel() == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b5e696a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 2, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic['num_pair'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10e767b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "mnist_train_data = torchvision.datasets.MNIST(root='./MNIST', train=True, download=True,transform=transform)\n",
    "mnist_test_data = torchvision.datasets.MNIST(root='./MNIST', train=False, download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3bfb7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import torch\n",
    "import codecs\n",
    "import string\n",
    "import gzip\n",
    "import lzma\n",
    "from typing import Any, Callable, Dict, IO, List, Optional, Tuple, Union\n",
    "\n",
    "def get_int(b: bytes) -> int:\n",
    "    return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "\n",
    "def open_maybe_compressed_file(path: Union[str, IO]) -> Union[IO, gzip.GzipFile]:\n",
    "    \"\"\"Return a file object that possibly decompresses 'path' on the fly.\n",
    "       Decompression occurs when argument `path` is a string and ends with '.gz' or '.xz'.\n",
    "    \"\"\"\n",
    "    if not isinstance(path, torch._six.string_classes):\n",
    "        return path\n",
    "    if path.endswith('.gz'):\n",
    "        return gzip.open(path, 'rb')\n",
    "    if path.endswith('.xz'):\n",
    "        return lzma.open(path, 'rb')\n",
    "    return open(path, 'rb')\n",
    "\n",
    "\n",
    "SN3_PASCALVINCENT_TYPEMAP = {\n",
    "    8: (torch.uint8, np.uint8, np.uint8),\n",
    "    9: (torch.int8, np.int8, np.int8),\n",
    "    11: (torch.int16, np.dtype('>i2'), 'i2'),\n",
    "    12: (torch.int32, np.dtype('>i4'), 'i4'),\n",
    "    13: (torch.float32, np.dtype('>f4'), 'f4'),\n",
    "    14: (torch.float64, np.dtype('>f8'), 'f8')\n",
    "}\n",
    "\n",
    "\n",
    "def read_sn3_pascalvincent_tensor(path: Union[str, IO], strict: bool = True) -> torch.Tensor:\n",
    "    \"\"\"Read a SN3 file in \"Pascal Vincent\" format (Lush file 'libidx/idx-io.lsh').\n",
    "       Argument may be a filename, compressed filename, or file object.\n",
    "    \"\"\"\n",
    "    # read\n",
    "    with open_maybe_compressed_file(path) as f:\n",
    "        data = f.read()\n",
    "    # parse\n",
    "    magic = get_int(data[0:4])\n",
    "    nd = magic % 256\n",
    "    ty = magic // 256\n",
    "    assert nd >= 1 and nd <= 3\n",
    "    assert ty >= 8 and ty <= 14\n",
    "    m = SN3_PASCALVINCENT_TYPEMAP[ty]\n",
    "    s = [get_int(data[4 * (i + 1): 4 * (i + 2)]) for i in range(nd)]\n",
    "    parsed = np.frombuffer(data, dtype=m[1], offset=(4 * (nd + 1)))\n",
    "    assert parsed.shape[0] == np.prod(s) or not strict\n",
    "    return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
    "\n",
    "\n",
    "def read_label_file(path: str) -> torch.Tensor:\n",
    "    with open(path, 'rb') as f:\n",
    "        x = read_sn3_pascalvincent_tensor(f, strict=False)\n",
    "    assert(x.dtype == torch.uint8)\n",
    "    assert(x.ndimension() == 1)\n",
    "    return x.long()\n",
    "\n",
    "\n",
    "def read_image_file(path: str) -> torch.Tensor:\n",
    "    with open(path, 'rb') as f:\n",
    "        x = read_sn3_pascalvincent_tensor(f, strict=False)\n",
    "    assert(x.dtype == torch.uint8)\n",
    "    assert(x.ndimension() == 3)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c236ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    " training_set = (\n",
    "            read_image_file(os.path.join(\"./MNIST/MNIST/raw/\", 'train-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(\"./MNIST/MNIST/raw/\", 'train-labels-idx1-ubyte'))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d426e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = training_set[0]\n",
    "targets = training_set[1]\n",
    "data = {'num_tuple_pair':[], 'num_concat_pair':[], 'summation': [],'summation_concat':[], 'formula':[]}\n",
    "zero_idx = []\n",
    "num_data = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2572250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "while num_data > 0:\n",
    "    i, j = torch.randint(len(targets), (1,)), torch.randint(len(targets), (1,))\n",
    "    tar1, tar2 = targets[i], targets[j]\n",
    "    \n",
    "    img1, img2 = imgs[i], imgs[j]\n",
    "    data['num_tuple_pair'].append((img1, img2))\n",
    "    img_pair = torch.cat((img1, img2))\n",
    "    data['num_concat_pair'].append(img_pair)\n",
    "    data['formula'].append(f\"{tar1.item()}+{tar2.item()}\")\n",
    "    data['summation'].append((tar1.item() + tar2.item()))\n",
    "    data['summation_concat'].append(torch.tensor(tar1.item() + tar2.item()))\n",
    "    num_data -= 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbaf0dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_concat_pair'] = torch.stack(tuple(data['num_concat_pair']))\n",
    "data['summation_concat'] = torch.stack(tuple(data['summation_concat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c44206c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data = {'num_pair':[],'summation':[], 'formula':[]}\n",
    "concat_data['num_pair'] = data['num_concat_pair']\n",
    "concat_data['summation'] = data['summation_concat']\n",
    "concat_data['formula'] = data['formula']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e6d70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tup = (concat_data['num_pair'], concat_data['summation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e26e47",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('./MNIST_pair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0691e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./MNIST_pair/training_tuple.pt\", 'wb') as f:\n",
    "        torch.save(tup, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f292d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./MNIST_pair/formula.pt\", 'wb') as f:\n",
    "        torch.save(tup[1], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56c3ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./MNIST_pair/training_dict.pt\", 'wb') as f:\n",
    "        torch.save(concat_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbecd222",
   "metadata": {},
   "outputs": [],
   "source": [
    "while num_data > 0:\n",
    "    i, j = torch.randint(len(targets), (1,)), torch.randint(len(targets), (1,))\n",
    "    tar1, tar2 = targets[i], targets[j]\n",
    "    if tar1 != 0 and tar2 != 0:\n",
    "        img1, img2 = imgs[i], imgs[j]\n",
    "        data['num_tuple_pair'].append((img1, img2))\n",
    "        img_pair = torch.cat((img1, img2))\n",
    "        data['num_concat_pair'].append(img_pair)\n",
    "        data['formula'].append(f\"{tar1.item()}+{tar2.item()}\")\n",
    "        data['summation'].append((tar1.item() +tar2.item()))\n",
    "        data['summation_concat'].append(torch.tensor(tar1.item()+tar2.item()))\n",
    "        num_data -= 1\n",
    "    \n",
    "    elif  targets[i] == 0 and  targets[j] == 0:\n",
    "        targets = torch.cat((targets[0:i], targets[i+1:]))\n",
    "        imgs = torch.cat((imgs[:i], imgs[i+1:]))\n",
    "        \n",
    "        targets = torch.cat((targets[0:j], targets[j+1:]))\n",
    "        imgs = torch.cat((imgs[:j], imgs[j+1:]))\n",
    "        \n",
    "    elif  targets[i] == 0 and  targets[j] != 0 :\n",
    "        targets = torch.cat((targets[0:i], targets[i+1:]))\n",
    "        imgs = torch.cat((imgs[:i], imgs[i+1:]))\n",
    "        \n",
    "    else:\n",
    "        targets = torch.cat((targets[0:j], targets[j+1:]))\n",
    "        imgs = torch.cat((imgs[:j], imgs[j+1:]))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
